{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\ImageClassification\n",
      "d:\\ImageClassification\\dataset\\feature_extractions_data.csv\n",
      "d:\\ImageClassification\n",
      "d:\\ImageClassification\\dataset\n",
      "File not found in the current directory.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "file_name = 'feature_extractions_data.csv'\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "file_path_feature_data=current_dir+'\\dataset'\n",
    "print(current_dir)\n",
    "# Combine the current working directory and the file name to get the full file path\n",
    "file_path = os.path.join(file_path_feature_data, file_name)\n",
    "print(file_path)\n",
    "\n",
    "\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "print(file_path_feature_data)\n",
    "# List all files in the current directory\n",
    "files_in_current_dir = os.listdir(current_dir)\n",
    "\n",
    "# Check if the file is in the current directory\n",
    "if file_name in files_in_current_dir:\n",
    "    print(\"File found.\")\n",
    "#     trad_df = pd.read_csv(file_path, index_col = False)\n",
    "else:\n",
    "    print(\"File not found in the current directory.\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contourArea</th>\n",
       "      <th>contourAspectRatio</th>\n",
       "      <th>contourCompactness</th>\n",
       "      <th>contourExtent</th>\n",
       "      <th>contourPerimeter</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117764.0</td>\n",
       "      <td>2.109705</td>\n",
       "      <td>18.349411</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>2.570220</td>\n",
       "      <td>Phrao District_12_June 2023_MHN_10_IMG_9634_ro...</td>\n",
       "      <td>MHN</td>\n",
       "      <td>D:\\ImageClassification\\dataset\\MHN\\Phrao Distr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107285.0</td>\n",
       "      <td>2.314815</td>\n",
       "      <td>19.007168</td>\n",
       "      <td>0.993380</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>2.545673</td>\n",
       "      <td>Phrao District_12_June 2023_MHN_10_IMG_9635_ro...</td>\n",
       "      <td>MHN</td>\n",
       "      <td>D:\\ImageClassification\\dataset\\MHN\\Phrao Distr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118762.0</td>\n",
       "      <td>2.092050</td>\n",
       "      <td>18.294370</td>\n",
       "      <td>0.993824</td>\n",
       "      <td>1474.0</td>\n",
       "      <td>2.464160</td>\n",
       "      <td>Phrao District_12_June 2023_MHN_11_IMG_9636_ro...</td>\n",
       "      <td>MHN</td>\n",
       "      <td>D:\\ImageClassification\\dataset\\MHN\\Phrao Distr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113273.0</td>\n",
       "      <td>2.192982</td>\n",
       "      <td>18.612591</td>\n",
       "      <td>0.993623</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>2.499509</td>\n",
       "      <td>Phrao District_12_June 2023_MHN_11_IMG_9637_ro...</td>\n",
       "      <td>MHN</td>\n",
       "      <td>D:\\ImageClassification\\dataset\\MHN\\Phrao Distr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118263.0</td>\n",
       "      <td>2.100840</td>\n",
       "      <td>18.321741</td>\n",
       "      <td>0.993807</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>2.340257</td>\n",
       "      <td>Phrao District_12_June 2023_MHN_12_IMG_9638_ro...</td>\n",
       "      <td>MHN</td>\n",
       "      <td>D:\\ImageClassification\\dataset\\MHN\\Phrao Distr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>224550.0</td>\n",
       "      <td>1.108647</td>\n",
       "      <td>16.042770</td>\n",
       "      <td>0.995787</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>1.118624</td>\n",
       "      <td>Singha Park_8_June 2023_R2E2_8-2_IMG_9241_rota...</td>\n",
       "      <td>R2E2</td>\n",
       "      <td>D:\\ImageClassification\\dataset\\R2E2\\Singha Par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>207085.0</td>\n",
       "      <td>1.201923</td>\n",
       "      <td>16.136292</td>\n",
       "      <td>0.995601</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>1.086224</td>\n",
       "      <td>Singha Park_8_June 2023_R2E2_9-1_IMG_9242_rota...</td>\n",
       "      <td>R2E2</td>\n",
       "      <td>D:\\ImageClassification\\dataset\\R2E2\\Singha Par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>222055.0</td>\n",
       "      <td>1.121076</td>\n",
       "      <td>16.052528</td>\n",
       "      <td>0.995762</td>\n",
       "      <td>1888.0</td>\n",
       "      <td>1.092457</td>\n",
       "      <td>Singha Park_8_June 2023_R2E2_9-1_IMG_9243_rota...</td>\n",
       "      <td>R2E2</td>\n",
       "      <td>D:\\ImageClassification\\dataset\\R2E2\\Singha Par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>199600.0</td>\n",
       "      <td>1.246883</td>\n",
       "      <td>16.196413</td>\n",
       "      <td>0.995511</td>\n",
       "      <td>1798.0</td>\n",
       "      <td>1.099648</td>\n",
       "      <td>Singha Park_8_June 2023_R2E2_9-2_IMG_9244_rota...</td>\n",
       "      <td>R2E2</td>\n",
       "      <td>D:\\ImageClassification\\dataset\\R2E2\\Singha Par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>220558.0</td>\n",
       "      <td>1.128668</td>\n",
       "      <td>16.058923</td>\n",
       "      <td>0.995747</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>1.080872</td>\n",
       "      <td>Singha Park_8_June 2023_R2E2_9-2_IMG_9245_rota...</td>\n",
       "      <td>R2E2</td>\n",
       "      <td>D:\\ImageClassification\\dataset\\R2E2\\Singha Par...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1544 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      contourArea  contourAspectRatio  contourCompactness  contourExtent  \\\n",
       "0        117764.0            2.109705           18.349411       0.993789   \n",
       "1        107285.0            2.314815           19.007168       0.993380   \n",
       "2        118762.0            2.092050           18.294370       0.993824   \n",
       "3        113273.0            2.192982           18.612591       0.993623   \n",
       "4        118263.0            2.100840           18.321741       0.993807   \n",
       "...           ...                 ...                 ...            ...   \n",
       "1539     224550.0            1.108647           16.042770       0.995787   \n",
       "1540     207085.0            1.201923           16.136292       0.995601   \n",
       "1541     222055.0            1.121076           16.052528       0.995762   \n",
       "1542     199600.0            1.246883           16.196413       0.995511   \n",
       "1543     220558.0            1.128668           16.058923       0.995747   \n",
       "\n",
       "      contourPerimeter  eccentricity  \\\n",
       "0               1470.0      2.570220   \n",
       "1               1428.0      2.545673   \n",
       "2               1474.0      2.464160   \n",
       "3               1452.0      2.499509   \n",
       "4               1472.0      2.340257   \n",
       "...                ...           ...   \n",
       "1539            1898.0      1.118624   \n",
       "1540            1828.0      1.086224   \n",
       "1541            1888.0      1.092457   \n",
       "1542            1798.0      1.099648   \n",
       "1543            1882.0      1.080872   \n",
       "\n",
       "                                               filename label  \\\n",
       "0     Phrao District_12_June 2023_MHN_10_IMG_9634_ro...   MHN   \n",
       "1     Phrao District_12_June 2023_MHN_10_IMG_9635_ro...   MHN   \n",
       "2     Phrao District_12_June 2023_MHN_11_IMG_9636_ro...   MHN   \n",
       "3     Phrao District_12_June 2023_MHN_11_IMG_9637_ro...   MHN   \n",
       "4     Phrao District_12_June 2023_MHN_12_IMG_9638_ro...   MHN   \n",
       "...                                                 ...   ...   \n",
       "1539  Singha Park_8_June 2023_R2E2_8-2_IMG_9241_rota...  R2E2   \n",
       "1540  Singha Park_8_June 2023_R2E2_9-1_IMG_9242_rota...  R2E2   \n",
       "1541  Singha Park_8_June 2023_R2E2_9-1_IMG_9243_rota...  R2E2   \n",
       "1542  Singha Park_8_June 2023_R2E2_9-2_IMG_9244_rota...  R2E2   \n",
       "1543  Singha Park_8_June 2023_R2E2_9-2_IMG_9245_rota...  R2E2   \n",
       "\n",
       "                                                   path  \n",
       "0     D:\\ImageClassification\\dataset\\MHN\\Phrao Distr...  \n",
       "1     D:\\ImageClassification\\dataset\\MHN\\Phrao Distr...  \n",
       "2     D:\\ImageClassification\\dataset\\MHN\\Phrao Distr...  \n",
       "3     D:\\ImageClassification\\dataset\\MHN\\Phrao Distr...  \n",
       "4     D:\\ImageClassification\\dataset\\MHN\\Phrao Distr...  \n",
       "...                                                 ...  \n",
       "1539  D:\\ImageClassification\\dataset\\R2E2\\Singha Par...  \n",
       "1540  D:\\ImageClassification\\dataset\\R2E2\\Singha Par...  \n",
       "1541  D:\\ImageClassification\\dataset\\R2E2\\Singha Par...  \n",
       "1542  D:\\ImageClassification\\dataset\\R2E2\\Singha Par...  \n",
       "1543  D:\\ImageClassification\\dataset\\R2E2\\Singha Par...  \n",
       "\n",
       "[1544 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trad_df = pd.read_csv(file_path, index_col = False)\n",
    "# trad_df.drop(\"Unnamed: 0\",axis=1,inplace=True)?\n",
    "# trad_df.drop(columns=[\"label\", \"filename\"], inplace=False)\n",
    "# trad_df[\"label\"]\n",
    "trad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contourArea</th>\n",
       "      <th>contourAspectRatio</th>\n",
       "      <th>contourCompactness</th>\n",
       "      <th>contourExtent</th>\n",
       "      <th>contourPerimeter</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117764.0</td>\n",
       "      <td>2.109705</td>\n",
       "      <td>18.349411</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>2.570220</td>\n",
       "      <td>MHN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107285.0</td>\n",
       "      <td>2.314815</td>\n",
       "      <td>19.007168</td>\n",
       "      <td>0.993380</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>2.545673</td>\n",
       "      <td>MHN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118762.0</td>\n",
       "      <td>2.092050</td>\n",
       "      <td>18.294370</td>\n",
       "      <td>0.993824</td>\n",
       "      <td>1474.0</td>\n",
       "      <td>2.464160</td>\n",
       "      <td>MHN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113273.0</td>\n",
       "      <td>2.192982</td>\n",
       "      <td>18.612591</td>\n",
       "      <td>0.993623</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>2.499509</td>\n",
       "      <td>MHN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118263.0</td>\n",
       "      <td>2.100840</td>\n",
       "      <td>18.321741</td>\n",
       "      <td>0.993807</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>2.340257</td>\n",
       "      <td>MHN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>224550.0</td>\n",
       "      <td>1.108647</td>\n",
       "      <td>16.042770</td>\n",
       "      <td>0.995787</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>1.118624</td>\n",
       "      <td>R2E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>207085.0</td>\n",
       "      <td>1.201923</td>\n",
       "      <td>16.136292</td>\n",
       "      <td>0.995601</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>1.086224</td>\n",
       "      <td>R2E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>222055.0</td>\n",
       "      <td>1.121076</td>\n",
       "      <td>16.052528</td>\n",
       "      <td>0.995762</td>\n",
       "      <td>1888.0</td>\n",
       "      <td>1.092457</td>\n",
       "      <td>R2E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>199600.0</td>\n",
       "      <td>1.246883</td>\n",
       "      <td>16.196413</td>\n",
       "      <td>0.995511</td>\n",
       "      <td>1798.0</td>\n",
       "      <td>1.099648</td>\n",
       "      <td>R2E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>220558.0</td>\n",
       "      <td>1.128668</td>\n",
       "      <td>16.058923</td>\n",
       "      <td>0.995747</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>1.080872</td>\n",
       "      <td>R2E2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1544 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      contourArea  contourAspectRatio  contourCompactness  contourExtent  \\\n",
       "0        117764.0            2.109705           18.349411       0.993789   \n",
       "1        107285.0            2.314815           19.007168       0.993380   \n",
       "2        118762.0            2.092050           18.294370       0.993824   \n",
       "3        113273.0            2.192982           18.612591       0.993623   \n",
       "4        118263.0            2.100840           18.321741       0.993807   \n",
       "...           ...                 ...                 ...            ...   \n",
       "1539     224550.0            1.108647           16.042770       0.995787   \n",
       "1540     207085.0            1.201923           16.136292       0.995601   \n",
       "1541     222055.0            1.121076           16.052528       0.995762   \n",
       "1542     199600.0            1.246883           16.196413       0.995511   \n",
       "1543     220558.0            1.128668           16.058923       0.995747   \n",
       "\n",
       "      contourPerimeter  eccentricity label  \n",
       "0               1470.0      2.570220   MHN  \n",
       "1               1428.0      2.545673   MHN  \n",
       "2               1474.0      2.464160   MHN  \n",
       "3               1452.0      2.499509   MHN  \n",
       "4               1472.0      2.340257   MHN  \n",
       "...                ...           ...   ...  \n",
       "1539            1898.0      1.118624  R2E2  \n",
       "1540            1828.0      1.086224  R2E2  \n",
       "1541            1888.0      1.092457  R2E2  \n",
       "1542            1798.0      1.099648  R2E2  \n",
       "1543            1882.0      1.080872  R2E2  \n",
       "\n",
       "[1544 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop string table\n",
    "trad_df = trad_df.drop(\"path\",axis = 1)\n",
    "trad_df = trad_df.drop(\"filename\",axis = 1)\n",
    "trad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_label = np.unique(trad_df['label'])\n",
    "int_label = []\n",
    "for l in trad_df['label']:\n",
    "  result = [x == l for x in unique_label]\n",
    "  i = np.argmax(result)\n",
    "  int_label.append(i)\n",
    "\n",
    "trad_df['label'] = int_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contourArea           float64\n",
       "contourAspectRatio    float64\n",
       "contourCompactness    float64\n",
       "contourExtent         float64\n",
       "contourPerimeter      float64\n",
       "eccentricity          float64\n",
       "label                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trad_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trad_df = trad_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contourArea           0\n",
       "contourAspectRatio    0\n",
       "contourCompactness    0\n",
       "contourExtent         0\n",
       "contourPerimeter      0\n",
       "eccentricity          0\n",
       "label                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trad_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trad_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# trad_df.replace(0, np.nan, inplace=True)\n",
    "trad_df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contourArea</th>\n",
       "      <th>contourAspectRatio</th>\n",
       "      <th>contourCompactness</th>\n",
       "      <th>contourExtent</th>\n",
       "      <th>contourPerimeter</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117764.0</td>\n",
       "      <td>2.109705</td>\n",
       "      <td>18.349411</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>2.570220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107285.0</td>\n",
       "      <td>2.314815</td>\n",
       "      <td>19.007168</td>\n",
       "      <td>0.993380</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>2.545673</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118762.0</td>\n",
       "      <td>2.092050</td>\n",
       "      <td>18.294370</td>\n",
       "      <td>0.993824</td>\n",
       "      <td>1474.0</td>\n",
       "      <td>2.464160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113273.0</td>\n",
       "      <td>2.192982</td>\n",
       "      <td>18.612591</td>\n",
       "      <td>0.993623</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>2.499509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118263.0</td>\n",
       "      <td>2.100840</td>\n",
       "      <td>18.321741</td>\n",
       "      <td>0.993807</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>2.340257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>224550.0</td>\n",
       "      <td>1.108647</td>\n",
       "      <td>16.042770</td>\n",
       "      <td>0.995787</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>1.118624</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>207085.0</td>\n",
       "      <td>1.201923</td>\n",
       "      <td>16.136292</td>\n",
       "      <td>0.995601</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>1.086224</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>222055.0</td>\n",
       "      <td>1.121076</td>\n",
       "      <td>16.052528</td>\n",
       "      <td>0.995762</td>\n",
       "      <td>1888.0</td>\n",
       "      <td>1.092457</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>199600.0</td>\n",
       "      <td>1.246883</td>\n",
       "      <td>16.196413</td>\n",
       "      <td>0.995511</td>\n",
       "      <td>1798.0</td>\n",
       "      <td>1.099648</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>220558.0</td>\n",
       "      <td>1.128668</td>\n",
       "      <td>16.058923</td>\n",
       "      <td>0.995747</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>1.080872</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1544 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      contourArea  contourAspectRatio  contourCompactness  contourExtent  \\\n",
       "0        117764.0            2.109705           18.349411       0.993789   \n",
       "1        107285.0            2.314815           19.007168       0.993380   \n",
       "2        118762.0            2.092050           18.294370       0.993824   \n",
       "3        113273.0            2.192982           18.612591       0.993623   \n",
       "4        118263.0            2.100840           18.321741       0.993807   \n",
       "...           ...                 ...                 ...            ...   \n",
       "1539     224550.0            1.108647           16.042770       0.995787   \n",
       "1540     207085.0            1.201923           16.136292       0.995601   \n",
       "1541     222055.0            1.121076           16.052528       0.995762   \n",
       "1542     199600.0            1.246883           16.196413       0.995511   \n",
       "1543     220558.0            1.128668           16.058923       0.995747   \n",
       "\n",
       "      contourPerimeter  eccentricity  label  \n",
       "0               1470.0      2.570220      0  \n",
       "1               1428.0      2.545673      0  \n",
       "2               1474.0      2.464160      0  \n",
       "3               1452.0      2.499509      0  \n",
       "4               1472.0      2.340257      0  \n",
       "...                ...           ...    ...  \n",
       "1539            1898.0      1.118624      2  \n",
       "1540            1828.0      1.086224      2  \n",
       "1541            1888.0      1.092457      2  \n",
       "1542            1798.0      1.099648      2  \n",
       "1543            1882.0      1.080872      2  \n",
       "\n",
       "[1544 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trad_df = trad_df.reindex(sorted(trad_df.columns), axis=1)\n",
    "# trad_df.to_csv('model_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contourArea</th>\n",
       "      <th>contourAspectRatio</th>\n",
       "      <th>contourCompactness</th>\n",
       "      <th>contourExtent</th>\n",
       "      <th>contourPerimeter</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117764.0</td>\n",
       "      <td>2.109705</td>\n",
       "      <td>18.349411</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>2.570220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107285.0</td>\n",
       "      <td>2.314815</td>\n",
       "      <td>19.007168</td>\n",
       "      <td>0.993380</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>2.545673</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118762.0</td>\n",
       "      <td>2.092050</td>\n",
       "      <td>18.294370</td>\n",
       "      <td>0.993824</td>\n",
       "      <td>1474.0</td>\n",
       "      <td>2.464160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113273.0</td>\n",
       "      <td>2.192982</td>\n",
       "      <td>18.612591</td>\n",
       "      <td>0.993623</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>2.499509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118263.0</td>\n",
       "      <td>2.100840</td>\n",
       "      <td>18.321741</td>\n",
       "      <td>0.993807</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>2.340257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>224550.0</td>\n",
       "      <td>1.108647</td>\n",
       "      <td>16.042770</td>\n",
       "      <td>0.995787</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>1.118624</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>207085.0</td>\n",
       "      <td>1.201923</td>\n",
       "      <td>16.136292</td>\n",
       "      <td>0.995601</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>1.086224</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>222055.0</td>\n",
       "      <td>1.121076</td>\n",
       "      <td>16.052528</td>\n",
       "      <td>0.995762</td>\n",
       "      <td>1888.0</td>\n",
       "      <td>1.092457</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>199600.0</td>\n",
       "      <td>1.246883</td>\n",
       "      <td>16.196413</td>\n",
       "      <td>0.995511</td>\n",
       "      <td>1798.0</td>\n",
       "      <td>1.099648</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>220558.0</td>\n",
       "      <td>1.128668</td>\n",
       "      <td>16.058923</td>\n",
       "      <td>0.995747</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>1.080872</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1544 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      contourArea  contourAspectRatio  contourCompactness  contourExtent  \\\n",
       "0        117764.0            2.109705           18.349411       0.993789   \n",
       "1        107285.0            2.314815           19.007168       0.993380   \n",
       "2        118762.0            2.092050           18.294370       0.993824   \n",
       "3        113273.0            2.192982           18.612591       0.993623   \n",
       "4        118263.0            2.100840           18.321741       0.993807   \n",
       "...           ...                 ...                 ...            ...   \n",
       "1539     224550.0            1.108647           16.042770       0.995787   \n",
       "1540     207085.0            1.201923           16.136292       0.995601   \n",
       "1541     222055.0            1.121076           16.052528       0.995762   \n",
       "1542     199600.0            1.246883           16.196413       0.995511   \n",
       "1543     220558.0            1.128668           16.058923       0.995747   \n",
       "\n",
       "      contourPerimeter  eccentricity  label  \n",
       "0               1470.0      2.570220      0  \n",
       "1               1428.0      2.545673      0  \n",
       "2               1474.0      2.464160      0  \n",
       "3               1452.0      2.499509      0  \n",
       "4               1472.0      2.340257      0  \n",
       "...                ...           ...    ...  \n",
       "1539            1898.0      1.118624      2  \n",
       "1540            1828.0      1.086224      2  \n",
       "1541            1888.0      1.092457      2  \n",
       "1542            1798.0      1.099648      2  \n",
       "1543            1882.0      1.080872      2  \n",
       "\n",
       "[1544 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for training purpose\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = trad_df.drop(\"label\",axis=1)\n",
    "y = trad_df[\"label\"]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2)\n",
    "X_test, X_validate, y_test, y_validate = train_test_split(X_val,y_val,test_size=0.5)\n",
    "\n",
    "# 8:1:1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from math import sqrt\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import (NeighborhoodComponentsAnalysis, KNeighborsClassifier)\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "# import joblib\n",
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelling\n",
    "\n",
    "def get_model(index = -1): \n",
    "  models = [\n",
    "  {\"name\": \"SVC\", \"model\": svm.SVC()},\n",
    "  {\n",
    "      \"name\" : \"ExtraTreesClassifier\",\n",
    "      \"model\" : ExtraTreesClassifier()\n",
    "  },\n",
    "  {\n",
    "      \"name\" : \"RandomForestClassifier\",\n",
    "      \"model\" : RandomForestClassifier()\n",
    "  },\n",
    "  {\n",
    "      \"name\" : \" KNeighborsClassifier\",\n",
    "      \"model\" :  KNeighborsClassifier()\n",
    "  },\n",
    "  {\n",
    "      \"name\" : \"DecisionTreeClassifier\",\n",
    "      \"model\" : tree.DecisionTreeClassifier()\n",
    "  },\n",
    "    {\n",
    "      \"name\" : \"GradientBoostingClassifier\",\n",
    "      \"model\" : GradientBoostingClassifier()\n",
    "  },\n",
    "    {\n",
    "      \"name\" : \"LogisticRegression\",\n",
    "      \"model\" : LogisticRegression()\n",
    "  },\n",
    "  {\n",
    "      \"name\" : \"AdaBoostClassifier\",\n",
    "      \"model\" : AdaBoostClassifier()\n",
    "  },\n",
    "  {\n",
    "      \"name\" : \"GaussianNB\",\n",
    "      \"model\" : GaussianNB()\n",
    "  },\n",
    "  {\n",
    "      \"name\" : \"BaggingClassifier\",\n",
    "      \"model\" : BaggingClassifier()\n",
    "  },\n",
    " {\n",
    "      \"name\" : \"LinearDiscriminantAnalysis\",\n",
    "      \"model\" : LinearDiscriminantAnalysis()\n",
    "  },\n",
    " {\n",
    "      \"name\" : \"QuadraticDiscriminantAnalysis\",\n",
    "      \"model\" : QuadraticDiscriminantAnalysis()\n",
    "  },\n",
    "  ]\n",
    "\n",
    "  if index == -1:\n",
    "    return len(models)\n",
    "\n",
    "  return models[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "def train_model_deep_learning(model):\n",
    "    print(\"Training by {} ...\".format(model[\"name\"]))\n",
    "\n",
    "    # Step 1: Train a Random Forest Model\n",
    "    m = model[\"model\"]\n",
    "    m.fit(X_train, y_train)\n",
    "    \n",
    "    # Step 2: Use Random Forest for Feature Selection (Note: This step seems to be misplaced)\n",
    "    feature_importances = m.feature_importances_\n",
    "    \n",
    "    # Select the top-k most important features\n",
    "    k = 10  # Adjust the number of selected features\n",
    "    selected_feature_indices = np.argsort(feature_importances)[::-1][:k]\n",
    "    X_train_selected = X_train[:, selected_feature_indices]\n",
    "    X_test_selected = X_val[:, selected_feature_indices]\n",
    "\n",
    "    # Step 3: Preprocess and Normalize Data (if needed)\n",
    "    # You may need to preprocess or normalize the selected features here.\n",
    "\n",
    "    # Step 4: Build a Deep Learning Model\n",
    "    num_classes = 10\n",
    "    deep_learning_model = Sequential()\n",
    "    deep_learning_model.add(Dense(64, activation='relu', input_shape=(k,)))\n",
    "    deep_learning_model.add(Dense(32, activation='relu'))\n",
    "    deep_learning_model.add(Dense(num_classes, activation='softmax'))  # Corrected line\n",
    "                            \n",
    "                            \n",
    "\n",
    "    # Step 5: Compile and Train the Deep Learning Model\n",
    "    deep_learning_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Assuming you have one-hot encoded labels for classification\n",
    "    y_train_one_hot = one_hot_encode(y_train)  # Implement one-hot encoding\n",
    "    y_test_one_hot = one_hot_encode(y_val)  # Implement one-hot encoding\n",
    "\n",
    "    deep_learning_model.fit(X_train_selected, y_train_one_hot, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "    # Step 6: Evaluate the Deep Learning Model\n",
    "    test_loss, test_accuracy = deep_learning_model.evaluate(X_test_selected, y_test_one_hot)\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "    # Step 7: Make Predictions\n",
    "    predictions = deep_learning_model.predict(X_test_selected)\n",
    "\n",
    "    score = m.score(X_val, y_val)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = m.predict(X_val)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred, average='weighted')\n",
    "    recall = recall_score(y_val, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "    \n",
    "    losses = mean_squared_error(y_val, y_pred)  # Adjust as needed\n",
    "    loss = f\"{losses:.4f}\"\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    \n",
    "    return m, score, precision, recall, f1, loss\n",
    "\n",
    "# You will need to define or load your data and implement one-hot encoding as needed.\n",
    "# X_train, y_train, X_val, y_val should be defined before calling the train_model_deep_learning function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "  print(\"Traning by {} ...\".format(model[\"name\"]))\n",
    "\n",
    "  m = model[\"model\"]\n",
    "  \n",
    "  m.fit(X_train,y_train)\n",
    "  modelFileName = model[\"name\"]+'model.pkl'\n",
    "  pickle.dump(m, open(modelFileName, 'wb'))\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2)\n",
    "# X_test, X_validate, y_test, y_validate = train_test_split(X_val,y_val,test_size=0.5)\n",
    "  \n",
    "  score = m.score(X_validate,y_validate)\n",
    "\n",
    "  # Make predictions on the test data\n",
    "  y_pred = m.predict(X_validate)\n",
    "\n",
    "  train_score = m.score(X_train,y_train)\n",
    "  print(f\"train_score: {train_score}\")\n",
    "\n",
    "  # Scoring the m on validation set\n",
    "  val_score = m.score(X_validate, y_validate)\n",
    "  \n",
    "  print(f\"val_score: {val_score}\")\n",
    "\n",
    "  # Scoring the m on test set\n",
    "  test_score = m.score(X_test, y_test)\n",
    "  print(f\"test_score: {test_score}\")\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "  accuracy = accuracy_score(y_validate, y_pred)\n",
    "  precision = precision_score(y_validate, y_pred, average='weighted')\n",
    "  recall = recall_score(y_validate, y_pred, average='weighted')\n",
    "  f1 = f1_score(y_validate, y_pred, average='weighted')\n",
    "#   losses = mean_squared_error(y_validate, y_pred,squared=False)\n",
    "  losses = mean_squared_error(y_validate, y_pred)\n",
    "  loss = f\"{losses:.4f}\"\n",
    "\n",
    "  print(f\"Accuracy: {accuracy}\")\n",
    "  print(f\"Precision: {precision}\")\n",
    "  print(f\"Recall: {recall}\")\n",
    "  print(f\"F1-score: {f1}\")\n",
    "  print(f\"Loss: {loss}\")\n",
    "  print(f\"Loss (MSE): {losses:.4f}\")\n",
    "\n",
    "  return m,score,precision,recall,f1,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning by SVC ...\n",
      "train_score: 0.8817813765182186\n",
      "val_score: 0.8516129032258064\n",
      "test_score: 0.8376623376623377\n",
      "Accuracy: 0.8516129032258064\n",
      "Precision: 0.8514549045424622\n",
      "Recall: 0.8516129032258064\n",
      "F1-score: 0.8514869486406489\n",
      "Loss: 0.1484\n",
      "Loss (MSE): 0.1484\n",
      "Traning by ExtraTreesClassifier ...\n",
      "train_score: 1.0\n",
      "val_score: 0.9741935483870968\n",
      "test_score: 0.9805194805194806\n",
      "Accuracy: 0.9741935483870968\n",
      "Precision: 0.9741935483870968\n",
      "Recall: 0.9741935483870968\n",
      "F1-score: 0.9741935483870968\n",
      "Loss: 0.0258\n",
      "Loss (MSE): 0.0258\n",
      "Traning by RandomForestClassifier ...\n",
      "train_score: 1.0\n",
      "val_score: 0.9870967741935484\n",
      "test_score: 0.987012987012987\n",
      "Accuracy: 0.9870967741935484\n",
      "Precision: 0.9875930521091812\n",
      "Recall: 0.9870967741935484\n",
      "F1-score: 0.987112041702109\n",
      "Loss: 0.0129\n",
      "Loss (MSE): 0.0129\n",
      "Traning by  KNeighborsClassifier ...\n",
      "train_score: 0.9546558704453442\n",
      "val_score: 0.9225806451612903\n",
      "test_score: 0.9025974025974026\n",
      "Accuracy: 0.9225806451612903\n",
      "Precision: 0.9225806451612903\n",
      "Recall: 0.9225806451612903\n",
      "F1-score: 0.9225806451612903\n",
      "Loss: 0.0774\n",
      "Loss (MSE): 0.0774\n",
      "Traning by DecisionTreeClassifier ...\n",
      "train_score: 1.0\n",
      "val_score: 0.9806451612903225\n",
      "test_score: 0.987012987012987\n",
      "Accuracy: 0.9806451612903225\n",
      "Precision: 0.980786931012672\n",
      "Recall: 0.9806451612903225\n",
      "F1-score: 0.9806582643376\n",
      "Loss: 0.0194\n",
      "Loss (MSE): 0.0194\n",
      "Traning by GradientBoostingClassifier ...\n",
      "train_score: 1.0\n",
      "val_score: 0.9741935483870968\n",
      "test_score: 0.987012987012987\n",
      "Accuracy: 0.9741935483870968\n",
      "Precision: 0.9747115928779766\n",
      "Recall: 0.9741935483870968\n",
      "F1-score: 0.9742240834042183\n",
      "Loss: 0.0258\n",
      "Loss (MSE): 0.0258\n",
      "Traning by LogisticRegression ...\n",
      "train_score: 0.8202429149797571\n",
      "val_score: 0.8129032258064516\n",
      "test_score: 0.7792207792207793\n",
      "Accuracy: 0.8129032258064516\n",
      "Precision: 0.832033523086654\n",
      "Recall: 0.8129032258064516\n",
      "F1-score: 0.8073190201067261\n",
      "Loss: 0.2258\n",
      "Loss (MSE): 0.2258\n",
      "Traning by AdaBoostClassifier ...\n",
      "train_score: 0.9870445344129555\n",
      "val_score: 0.9806451612903225\n",
      "test_score: 0.987012987012987\n",
      "Accuracy: 0.9806451612903225\n",
      "Precision: 0.980786931012672\n",
      "Recall: 0.9806451612903225\n",
      "F1-score: 0.9806582643376\n",
      "Loss: 0.0194\n",
      "Loss (MSE): 0.0194\n",
      "Traning by GaussianNB ...\n",
      "train_score: 0.6607287449392713\n",
      "val_score: 0.6193548387096774\n",
      "test_score: 0.6753246753246753\n",
      "Accuracy: 0.6193548387096774\n",
      "Precision: 0.6359801488833747\n",
      "Recall: 0.6193548387096774\n",
      "F1-score: 0.5297386484483259\n",
      "Loss: 0.3806\n",
      "Loss (MSE): 0.3806\n",
      "Traning by BaggingClassifier ...\n",
      "train_score: 0.9991902834008097\n",
      "val_score: 0.9806451612903225\n",
      "test_score: 0.987012987012987\n",
      "Accuracy: 0.9806451612903225\n",
      "Precision: 0.9817407181984176\n",
      "Recall: 0.9806451612903225\n",
      "F1-score: 0.9806745734555209\n",
      "Loss: 0.0194\n",
      "Loss (MSE): 0.0194\n",
      "Traning by LinearDiscriminantAnalysis ...\n",
      "train_score: 0.9838056680161943\n",
      "val_score: 0.9806451612903225\n",
      "test_score: 0.987012987012987\n",
      "Accuracy: 0.9806451612903225\n",
      "Precision: 0.980786931012672\n",
      "Recall: 0.9806451612903225\n",
      "F1-score: 0.9806582643376\n",
      "Loss: 0.0194\n",
      "Loss (MSE): 0.0194\n",
      "Traning by QuadraticDiscriminantAnalysis ...\n",
      "train_score: 0.968421052631579\n",
      "val_score: 0.9612903225806452\n",
      "test_score: 0.9805194805194806\n",
      "Accuracy: 0.9612903225806452\n",
      "Precision: 0.9612903225806452\n",
      "Recall: 0.9612903225806452\n",
      "F1-score: 0.9612903225806452\n",
      "Loss: 0.0387\n",
      "Loss (MSE): 0.0387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xzodu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "## main execution\n",
    "\n",
    "models = []\n",
    "scores = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "loss = []\n",
    "work_model= []\n",
    "\n",
    "for i in range(get_model()):\n",
    "  model_wrapper = get_model(i)\n",
    "  model = model_wrapper[\"model\"]\n",
    "  model_name = model_wrapper[\"name\"]\n",
    "  # train_model_deep_learning(model_wrapper)\n",
    "\n",
    "  m,score,precision,recall,f1,losses = train_model(model_wrapper)\n",
    "  # train_model_deep_learning(model_wrapper)\n",
    "  models.append(model_name)\n",
    "  scores.append(score)\n",
    "  precisions.append(precision)\n",
    "  recalls.append(recall)\n",
    "  f1s.append(f1)\n",
    "  loss.append(losses)\n",
    "  work_model.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def generate_score_df(models = models, scores = scores, precision = precisions, recall = recalls, f1 = f1s,loss = loss ):\n",
    "  df_scores = pd.DataFrame(np.array([models,scores,precision,recall,f1,loss]).T,columns=[\"model_name\",\"Accuracy\",\"precision\",\"recall\",\"f1\",\"loss\"])\n",
    "  df_scores.to_csv('test_current_score.csv',index=False)\n",
    "  return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.8516129032258064</td>\n",
       "      <td>0.8514549045424622</td>\n",
       "      <td>0.8516129032258064</td>\n",
       "      <td>0.8514869486406489</td>\n",
       "      <td>0.1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.9741935483870968</td>\n",
       "      <td>0.9741935483870968</td>\n",
       "      <td>0.9741935483870968</td>\n",
       "      <td>0.9741935483870968</td>\n",
       "      <td>0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.9870967741935484</td>\n",
       "      <td>0.9875930521091812</td>\n",
       "      <td>0.9870967741935484</td>\n",
       "      <td>0.987112041702109</td>\n",
       "      <td>0.0129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.9225806451612903</td>\n",
       "      <td>0.9225806451612903</td>\n",
       "      <td>0.9225806451612903</td>\n",
       "      <td>0.9225806451612903</td>\n",
       "      <td>0.0774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.9806451612903225</td>\n",
       "      <td>0.980786931012672</td>\n",
       "      <td>0.9806451612903225</td>\n",
       "      <td>0.9806582643376</td>\n",
       "      <td>0.0194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.9741935483870968</td>\n",
       "      <td>0.9747115928779766</td>\n",
       "      <td>0.9741935483870968</td>\n",
       "      <td>0.9742240834042183</td>\n",
       "      <td>0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8129032258064516</td>\n",
       "      <td>0.832033523086654</td>\n",
       "      <td>0.8129032258064516</td>\n",
       "      <td>0.8073190201067261</td>\n",
       "      <td>0.2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.9806451612903225</td>\n",
       "      <td>0.980786931012672</td>\n",
       "      <td>0.9806451612903225</td>\n",
       "      <td>0.9806582643376</td>\n",
       "      <td>0.0194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.6193548387096774</td>\n",
       "      <td>0.6359801488833747</td>\n",
       "      <td>0.6193548387096774</td>\n",
       "      <td>0.5297386484483259</td>\n",
       "      <td>0.3806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.9806451612903225</td>\n",
       "      <td>0.9817407181984176</td>\n",
       "      <td>0.9806451612903225</td>\n",
       "      <td>0.9806745734555209</td>\n",
       "      <td>0.0194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9806451612903225</td>\n",
       "      <td>0.980786931012672</td>\n",
       "      <td>0.9806451612903225</td>\n",
       "      <td>0.9806582643376</td>\n",
       "      <td>0.0194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.9612903225806452</td>\n",
       "      <td>0.9612903225806452</td>\n",
       "      <td>0.9612903225806452</td>\n",
       "      <td>0.9612903225806452</td>\n",
       "      <td>0.0387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model_name            Accuracy           precision  \\\n",
       "0                             SVC  0.8516129032258064  0.8514549045424622   \n",
       "1            ExtraTreesClassifier  0.9741935483870968  0.9741935483870968   \n",
       "2          RandomForestClassifier  0.9870967741935484  0.9875930521091812   \n",
       "3            KNeighborsClassifier  0.9225806451612903  0.9225806451612903   \n",
       "4          DecisionTreeClassifier  0.9806451612903225   0.980786931012672   \n",
       "5      GradientBoostingClassifier  0.9741935483870968  0.9747115928779766   \n",
       "6              LogisticRegression  0.8129032258064516   0.832033523086654   \n",
       "7              AdaBoostClassifier  0.9806451612903225   0.980786931012672   \n",
       "8                      GaussianNB  0.6193548387096774  0.6359801488833747   \n",
       "9               BaggingClassifier  0.9806451612903225  0.9817407181984176   \n",
       "10     LinearDiscriminantAnalysis  0.9806451612903225   0.980786931012672   \n",
       "11  QuadraticDiscriminantAnalysis  0.9612903225806452  0.9612903225806452   \n",
       "\n",
       "                recall                  f1    loss  \n",
       "0   0.8516129032258064  0.8514869486406489  0.1484  \n",
       "1   0.9741935483870968  0.9741935483870968  0.0258  \n",
       "2   0.9870967741935484   0.987112041702109  0.0129  \n",
       "3   0.9225806451612903  0.9225806451612903  0.0774  \n",
       "4   0.9806451612903225     0.9806582643376  0.0194  \n",
       "5   0.9741935483870968  0.9742240834042183  0.0258  \n",
       "6   0.8129032258064516  0.8073190201067261  0.2258  \n",
       "7   0.9806451612903225     0.9806582643376  0.0194  \n",
       "8   0.6193548387096774  0.5297386484483259  0.3806  \n",
       "9   0.9806451612903225  0.9806745734555209  0.0194  \n",
       "10  0.9806451612903225     0.9806582643376  0.0194  \n",
       "11  0.9612903225806452  0.9612903225806452  0.0387  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_score_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # Assume you have a dataset with features (X) and labels (y)\n",
    "# # X and y should be NumPy arrays or pandas DataFrames\n",
    "\n",
    "# # Split the dataset into training and testing sets\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# X_test=X_val\n",
    "# y_test =y_val\n",
    "# # Initialize a Sequential model\n",
    "# model = Sequential()\n",
    "\n",
    "# # Add layers to the model\n",
    "# model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# # Evaluate the model\n",
    "# _, accuracy = model.evaluate(X_test, y_test)\n",
    "# print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# import numpy as np\n",
    "\n",
    "# def train_model_deep_learning(model):\n",
    "#     print(\"Training by {} ...\".format(model[\"name\"]))\n",
    "\n",
    "#     # Step 1: Train a Random Forest Model\n",
    "#     m = model[\"model\"]\n",
    "#     m.fit(X_train, y_train)\n",
    "    \n",
    "#     # Step 2: Use Random Forest for Feature Selection (Note: This step seems to be misplaced)\n",
    "#     feature_importances = m.feature_importances_\n",
    "    \n",
    "#     # Select the top-k most important features\n",
    "#     k = 10  # Adjust the number of selected features\n",
    "#     selected_feature_indices = np.argsort(feature_importances)[::-1][:k]\n",
    "#     X_train_selected = X_train[:, selected_feature_indices]\n",
    "#     X_test_selected = X_val[:, selected_feature_indices]\n",
    "\n",
    "#     # Step 3: Preprocess and Normalize Data (if needed)\n",
    "#     # You may need to preprocess or normalize the selected features here.\n",
    "\n",
    "#     # Step 4: Build a Deep Learning Model\n",
    "#     num_classes = 10\n",
    "#     deep_learning_model = Sequential()\n",
    "#     deep_learning_model.add(Dense(64, activation='relu', input_shape=(k,)))\n",
    "#     deep_learning_model.add(Dense(32, activation='relu'))\n",
    "#     deep_learning_model.add(Dense(num_classes, activation='softmax'))  # Corrected line\n",
    "                            \n",
    "                            \n",
    "\n",
    "#     # Step 5: Compile and Train the Deep Learning Model\n",
    "#     deep_learning_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     # Assuming you have one-hot encoded labels for classification\n",
    "#     y_train_one_hot = one_hot_encode(y_train)  # Implement one-hot encoding\n",
    "#     y_test_one_hot = one_hot_encode(y_val)  # Implement one-hot encoding\n",
    "\n",
    "#     deep_learning_model.fit(X_train_selected, y_train_one_hot, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "#     # Step 6: Evaluate the Deep Learning Model\n",
    "#     test_loss, test_accuracy = deep_learning_model.evaluate(X_test_selected, y_test_one_hot)\n",
    "#     print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "#     # Step 7: Make Predictions\n",
    "#     predictions = deep_learning_model.predict(X_test_selected)\n",
    "\n",
    "#     score = m.score(X_val, y_val)\n",
    "\n",
    "#     # Make predictions on the test data\n",
    "#     y_pred = m.predict(X_val)\n",
    "\n",
    "#     # Calculate evaluation metrics\n",
    "#     accuracy = accuracy_score(y_val, y_pred)\n",
    "#     precision = precision_score(y_val, y_pred, average='weighted')\n",
    "#     recall = recall_score(y_val, y_pred, average='weighted')\n",
    "#     f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "    \n",
    "#     losses = mean_squared_error(y_val, y_pred)  # Adjust as needed\n",
    "#     loss = f\"{losses:.4f}\"\n",
    "    \n",
    "#     print(f\"Accuracy: {accuracy}\")\n",
    "    \n",
    "#     return m, score, precision, recall, f1, loss\n",
    "\n",
    "# # You will need to define or load your data and implement one-hot encoding as needed.\n",
    "# # X_train, y_train, X_val, y_val should be defined before calling the train_model_deep_learning function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
